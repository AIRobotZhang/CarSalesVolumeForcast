{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import gc\n",
    "import math\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = 'D:/MyDocument/Project/CarSalesPrediction/'\n",
    "\n",
    "train_sales  = pd.read_csv(path+'train2_dataset/train_sales_data.csv')\n",
    "train_search = pd.read_csv(path+'train2_dataset/train_search_data.csv')\n",
    "train_user_reply = pd.read_csv(path+'train2_dataset/train_user_reply_data.csv')\n",
    "evaluation_public = pd.read_csv(path+'test2_dataset/evaluation_public.csv')\n",
    "data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = data.merge(train_user_reply, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "data['label'] = data['salesVolume']\n",
    "data['id'] = data['id'].fillna(0).astype(int)\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "data['mt'] = (data['regYear']-2016)*12+data['regMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salesVolume</th>\n",
       "      <th>adcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>389.0</td>\n",
       "      <td>310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>306.0</td>\n",
       "      <td>530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>260.0</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>757.0</td>\n",
       "      <td>510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>275.0</td>\n",
       "      <td>340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>890.0</td>\n",
       "      <td>370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>387.0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8330.0</td>\n",
       "      <td>440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>801.0</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1685.0</td>\n",
       "      <td>320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>393.0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>788.0</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>850.0</td>\n",
       "      <td>410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1438.0</td>\n",
       "      <td>330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>762.0</td>\n",
       "      <td>420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>678.0</td>\n",
       "      <td>430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1115.0</td>\n",
       "      <td>350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1304.0</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>188.0</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>240.0</td>\n",
       "      <td>610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>467.0</td>\n",
       "      <td>230000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salesVolume  adcode\n",
       "22        389.0  310000\n",
       "23        306.0  530000\n",
       "24        260.0  150000\n",
       "26        757.0  510000\n",
       "27        275.0  340000\n",
       "28        890.0  370000\n",
       "29        387.0  140000\n",
       "30       8330.0  440000\n",
       "31        801.0  450000\n",
       "32       1685.0  320000\n",
       "33        393.0  360000\n",
       "34        788.0  130000\n",
       "35        850.0  410000\n",
       "36       1438.0  330000\n",
       "37        762.0  420000\n",
       "38        678.0  430000\n",
       "39       1115.0  350000\n",
       "40       1304.0  210000\n",
       "41        188.0  500000\n",
       "42        240.0  610000\n",
       "43        467.0  230000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data['regMonth']==1) & (data['regYear']==2016) & (data['model']==1) & (data['adcode'] != 110000)][['salesVolume','adcode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'上海'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0]['province']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_stat_feature(df_):   \n",
    "#     df = df_.copy()\n",
    "#     stat_feat = []\n",
    "#     y = []\n",
    "#     df['model_adcode'] = df['adcode'] + df['model']\n",
    "#     df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "#     for col in tqdm(['salesVolume','popularity','carCommentVolum','newsReplyVolum',\\\n",
    "#                'adcode_year_month_sales_all','adcode_year_month_bodyType_sales_all','model_year_month_sales_all']):\n",
    "#         # shift\n",
    "#         for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "#             stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "#             df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "#             df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "#             df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "    \n",
    "#     for col in tqdm(['salesVolume','popularity','carCommentVolum','newsReplyVolum',\\\n",
    "#                'adcode_year_month_sales_all','adcode_year_month_bodyType_sales_all','model_year_month_sales_all']):\n",
    "#         # shift\n",
    "#         for pair in [(1,2), (1,3), (2,3), (2,4), (3,4), (3,5), (1,6), (2,6), (1,12)]:\n",
    "#             stat_feat.append('rise_model_adcode_mt_{}_{}_{}'.format(col,pair[0],pair[1]))\n",
    "#             df['rise_model_adcode_mt_{}_{}_{}'.format(col,pair[0],pair[1])] = df['shift_model_adcode_mt_{}_{}'.format(col,pair[0])] - df['shift_model_adcode_mt_{}_{}'.format(col,pair[1])]\n",
    "\n",
    "#     for col in tqdm(['salesVolume', 'adcode_year_month_sales_all','adcode_year_month_bodyType_sales_all','model_year_month_sales_all']):\n",
    "#         # history feature delta\n",
    "#         for pair in [(1,2), (1,3), (2,3), (2,4), (3,4), (3,5), (1,6), (1,12)]:\n",
    "#             stat_feat.append('ratio_model_adcode_mt_{}_{}_{}'.format(col,pair[0],pair[1]))\n",
    "#             df['ratio_model_adcode_mt_{}_{}_{}'.format(col,pair[0],pair[1])] = df['shift_model_adcode_mt_{}_{}'.format(col,pair[0])] \\\n",
    "#                                                / (df['shift_model_adcode_mt_{}_{}'.format(col,pair[1])])\n",
    "\n",
    "#     for col in tqdm(['salesVolume']):\n",
    "#         for i in [0,1,2,3]:\n",
    "#             y.append('after_model_adcode_mt_{}_{}'.format(col,i))\n",
    "#             df['model_adcode_mt_{}_{}'.format(col,-i)] = df['model_adcode_mt'] - i\n",
    "#             df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,-i))\n",
    "#             df['after_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "#     return df,stat_feat,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_feature(df_,): \n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    stat_feat_2=[]\n",
    "    stat_feat_3 = []\n",
    "    stat_feat_4 = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "    for col in ['label']:\n",
    "        # 历史销量数据特征\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "    for col in ['popularity','carCommentVolum','newsReplyVolum']:\n",
    "        # 历史popularity数据特征\n",
    "        for i in [5,10,11,12]:# popularity只取一部分\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "    \n",
    "    pairs = [(1,13), (2,14), (3,15), (4,16)]\n",
    "    for col in ['label']:\n",
    "        # 比去年同期增长多少(同比一年前的增长)\n",
    "        for pair in pairs:\n",
    "            stat_feat.append('increase_{}_{}_{}'.format(col,pair[0],pair[1]))\n",
    "            df['increase_{}_{}_{}'.format(col,pair[0],pair[1])] = (df['shift_model_adcode_mt_{}_{}'.format(col,pair[0])]-\n",
    "                df['shift_model_adcode_mt_{}_{}'.format(col,pair[1])])/df['shift_model_adcode_mt_{}_{}'.format(col,pair[1])]\n",
    "        # 过去一段时间的mean, max, median, min, std, diff\n",
    "        for width in [(1,4), (1,7), (1,5), (7,13), (3,6), (3,9)]:\n",
    "            item = []\n",
    "            for ii in range(width[0],width[1]):\n",
    "                item.append('shift_model_adcode_mt_{}_{}'.format(col,ii))\n",
    "            df['diff_{}_{}'.format(col,width)] = df[item].diff(axis=1).mean(axis=1)\n",
    "            stat_feat.append('diff_{}_{}'.format(col,width))\n",
    "            df['mean_{}_{}'.format(col,width)] = df[item].mean(axis=1)\n",
    "            stat_feat.append('mean_{}_{}'.format(col,width))\n",
    "            df['max_{}_{}'.format(col,width)] = df[item].max(axis=1)\n",
    "            stat_feat.append('max_{}_{}'.format(col,width))\n",
    "            df['min_{}_{}'.format(col,width)] = df[item].min(axis=1)\n",
    "            stat_feat.append('min_{}_{}'.format(col,width))\n",
    "            df['std_{}_{}'.format(col,width)] = df[item].std(axis=1)\n",
    "            stat_feat.append('std_{}_{}'.format(col,width))\n",
    "            df['median_{}_{}'.format(col,width)] = df[item].median(axis=1)\n",
    "            stat_feat.append('median_{}_{}'.format(col,width))\n",
    "\n",
    "        # 按车型或省份每月mean和min\n",
    "        for ind in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            stat_feat.append('Mean_model_{}_{}'.format(col,ind))\n",
    "            stat_feat.append('Min_model_{}_{}'.format(col,ind))\n",
    "            stat_feat.append('Median_model_{}_{}'.format(col,ind))\n",
    "            stat_feat.append('Max_model_{}_{}'.format(col,ind))\n",
    "            stat_feat.append('Std_model_{}_{}'.format(col,ind))\n",
    "            #  stat_feat.append('Diff_model_{}_{}'.format(col,ind))\n",
    "            \n",
    "            mean = pd.DataFrame(df.groupby(['model','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].mean()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Mean_model_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "            min_ = pd.DataFrame(df.groupby(['model','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].min()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Min_model_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,min_,on=[\"model\",\"mt\"],how=\"left\")\n",
    "            max_ = pd.DataFrame(df.groupby(['model','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].max()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Max_model_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,max_,on=[\"model\",\"mt\"],how=\"left\")\n",
    "            median_ = pd.DataFrame(df.groupby(['model','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].median()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Median_model_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,median_,on=[\"model\",\"mt\"],how=\"left\")\n",
    "            std_ = pd.DataFrame(df.groupby(['model','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].std()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Std_model_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,std_,on=[\"model\",\"mt\"],how=\"left\")\n",
    "            #  diff_ = pd.DataFrame(df.groupby(['model','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].diff().mean()).rename(\n",
    "            #      columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Diff_model_{}_{}'.format(col,ind)})\n",
    "            #  df = pd.merge(df,diff_,on=[\"model\",\"mt\"],how=\"left\")\n",
    "            \n",
    "            stat_feat.append('Mean_adcode_{}_{}'.format(col,ind))\n",
    "            stat_feat.append('Min_adcode_{}_{}'.format(col,ind))\n",
    "            stat_feat.append('Median_adcode_{}_{}'.format(col,ind))\n",
    "            stat_feat.append('Max_adcode_{}_{}'.format(col,ind))\n",
    "            stat_feat.append('Std_adcode_{}_{}'.format(col,ind))\n",
    "            #  stat_feat.append('Diff_adcode_{}_{}'.format(col,ind))\n",
    "            mean = pd.DataFrame(df.groupby(['adcode','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].mean()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Mean_adcode_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\")\n",
    "            min_ = pd.DataFrame(df.groupby(['adcode','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].min()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Min_adcode_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,min_,on=[\"adcode\",\"mt\"],how=\"left\")\n",
    "            max_ = pd.DataFrame(df.groupby(['adcode','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].max()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Max_adcode_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,max_,on=[\"adcode\",\"mt\"],how=\"left\")\n",
    "            median_ = pd.DataFrame(df.groupby(['adcode','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].median()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Median_adcode_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,median_,on=[\"adcode\",\"mt\"],how=\"left\")\n",
    "            std_ = pd.DataFrame(df.groupby(['adcode','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].std()).rename(\n",
    "                columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Std_adcode_{}_{}'.format(col,ind)})\n",
    "            df = pd.merge(df,std_,on=[\"adcode\",\"mt\"],how=\"left\")\n",
    "            #  diff_ = pd.DataFrame(df.groupby(['adcode','mt'])['shift_model_adcode_mt_{}_{}'.format(col,ind)].diff().mean()).rename(\n",
    "            #     columns={'shift_model_adcode_mt_{}_{}'.format(col,ind):'Diff_adcode_{}_{}'.format(col,ind)})\n",
    "            #  df = pd.merge(df,diff_,on=[\"adcode\",\"mt\"],how=\"left\")\n",
    "    pairs = [(1,4), (1,6), (1,12), (3,6), (3,12),(3,9)]\n",
    "    for col in ['label']:\n",
    "        # mean model/adcode 增长比例\n",
    "        for pair in pairs:\n",
    "            stat_feat.append('increase_mean_model_{}_{}_{}'.format(col,pair[0],pair[1]))\n",
    "            df['increase_mean_model_{}_{}_{}'.format(col,pair[0],pair[1])] = (df['Mean_model_{}_{}'.format(col,pair[0])]-\n",
    "                df['Mean_model_{}_{}'.format(col,pair[1])])/df['Mean_model_{}_{}'.format(col,pair[1])]\n",
    "            stat_feat.append('increase_mean_adcode_{}_{}_{}'.format(col,pair[0],pair[1]))\n",
    "            df['increase_mean_adcode_{}_{}_{}'.format(col,pair[0],pair[1])] = (df['Mean_adcode_{}_{}'.format(col,pair[0])]-\n",
    "                df['Mean_adcode_{}_{}'.format(col,pair[1])])/df['Mean_adcode_{}_{}'.format(col,pair[1])]\n",
    "    \n",
    "    for col in ['label']:\n",
    "        # sum求和\n",
    "        ind = 0\n",
    "        for pair in [(1,2,11,12),(1,2,3),(1,12)]:\n",
    "            stat_feat.append('sum_{}_{}'.format(col,ind))\n",
    "            df['sum_{}_{}'.format(col,ind)] = 0\n",
    "            length = len(pair)\n",
    "            for i in range(length):\n",
    "                df['sum_{}_{}'.format(col,ind)] += df[\"shift_model_adcode_mt_{}_{}\".format(col,pair[i])].values\n",
    "            ind += 1\n",
    "            \n",
    "    # 删除特征\n",
    "    #  stat_feat.remove(\"shift_model_adcode_mt_label_15\")\n",
    "    y =[]\n",
    "    for col in tqdm(['salesVolume']):\n",
    "        for i in [0,1,2,3]:\n",
    "            y.append('after_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,-i)] = df['model_adcode_mt'] - i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,-i))\n",
    "            df['after_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "    return df,stat_feat,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "#     data['label'] = np.expm1(data['label'].values)\n",
    "#     data['pred_label'] = np.expm1(data['pred_label'].values)\n",
    "#     data['label'] = np.expm1(data['label'].values)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='rmse',\n",
    "                                max_depth=-1, learning_rate=0.008, min_child_samples=5, random_state=2019,\n",
    "                                n_estimators=4000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        #  model = BaggingRegressor(model, n_estimators=8, random_state=0, n_jobs=1, max_samples=0.9,)\n",
    "        #  model.fit(train_x, train_y)\n",
    "        \n",
    "        model.fit(train_x, train_y, \n",
    "                      eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "                      categorical_feature=cate_feat, \n",
    "                      early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_model(df_, m, y, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , 21))\n",
    "    train_idx = (df['mt'].between(st , 20))\n",
    "    valid_idx = (df['mt'].between(21, 21))\n",
    "    test_idx  = (df['mt'].between(25, 25))\n",
    "\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx][y]\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx][y]   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)  \n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    # df['pred_label'] = np.expm1(df['pred_label'].values)\n",
    "    best_score = score(df[valid_idx],label=y) \n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_+100\n",
    "        model.fit(df[all_idx][features], df[all_idx][y])\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration+100\n",
    "        model.fit(df[all_idx][features], df[all_idx][y])\n",
    "    df['forecastVolum'] = model.predict(df[features]) \n",
    "    # df['forecastVolum'] = np.expm1(df['forecastVolum'].values)\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx][y].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)  \n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 208\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 303.676\tvalid_1's rmse: 387.869\n",
      "[200]\ttraining's rmse: 174.214\tvalid_1's rmse: 235.694\n",
      "[300]\ttraining's rmse: 120.526\tvalid_1's rmse: 178.53\n",
      "[400]\ttraining's rmse: 96.811\tvalid_1's rmse: 160.466\n",
      "[500]\ttraining's rmse: 84.0229\tvalid_1's rmse: 153.77\n",
      "[600]\ttraining's rmse: 75.456\tvalid_1's rmse: 150.417\n",
      "[700]\ttraining's rmse: 68.9314\tvalid_1's rmse: 148.776\n",
      "[800]\ttraining's rmse: 64.2168\tvalid_1's rmse: 147.499\n",
      "[900]\ttraining's rmse: 60.343\tvalid_1's rmse: 146.907\n",
      "[1000]\ttraining's rmse: 57.1868\tvalid_1's rmse: 146.607\n",
      "[1100]\ttraining's rmse: 54.5083\tvalid_1's rmse: 146.316\n",
      "[1200]\ttraining's rmse: 52.1953\tvalid_1's rmse: 146.14\n",
      "[1300]\ttraining's rmse: 50.2049\tvalid_1's rmse: 145.956\n",
      "[1400]\ttraining's rmse: 48.4904\tvalid_1's rmse: 145.934\n",
      "[1500]\ttraining's rmse: 46.9\tvalid_1's rmse: 145.827\n",
      "[1600]\ttraining's rmse: 45.4314\tvalid_1's rmse: 145.78\n",
      "[1700]\ttraining's rmse: 44.095\tvalid_1's rmse: 145.686\n",
      "[1800]\ttraining's rmse: 42.8298\tvalid_1's rmse: 145.65\n",
      "[1900]\ttraining's rmse: 41.6609\tvalid_1's rmse: 145.603\n",
      "[2000]\ttraining's rmse: 40.5809\tvalid_1's rmse: 145.576\n",
      "Early stopping, best iteration is:\n",
      "[1987]\ttraining's rmse: 40.7268\tvalid_1's rmse: 145.567\n",
      "0.7805796201556083\n",
      "valid mean: 530.1821801917343\n",
      "true  mean: 559.0532150776053\n",
      "test  mean: 498.7759667933048\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 313.237\tvalid_1's rmse: 368.932\n",
      "[200]\ttraining's rmse: 177.872\tvalid_1's rmse: 231.666\n",
      "[300]\ttraining's rmse: 121.348\tvalid_1's rmse: 193.952\n",
      "[400]\ttraining's rmse: 97.1197\tvalid_1's rmse: 185.398\n",
      "[500]\ttraining's rmse: 84.6713\tvalid_1's rmse: 184.776\n",
      "[600]\ttraining's rmse: 76.48\tvalid_1's rmse: 183.872\n",
      "[700]\ttraining's rmse: 70.3714\tvalid_1's rmse: 183.283\n",
      "[800]\ttraining's rmse: 65.581\tvalid_1's rmse: 182.585\n",
      "[900]\ttraining's rmse: 61.8489\tvalid_1's rmse: 181.904\n",
      "[1000]\ttraining's rmse: 58.9098\tvalid_1's rmse: 181.567\n",
      "[1100]\ttraining's rmse: 56.3288\tvalid_1's rmse: 181.219\n",
      "[1200]\ttraining's rmse: 54.0919\tvalid_1's rmse: 180.805\n",
      "[1300]\ttraining's rmse: 52.0435\tvalid_1's rmse: 180.559\n",
      "[1400]\ttraining's rmse: 50.2307\tvalid_1's rmse: 180.432\n",
      "[1500]\ttraining's rmse: 48.6065\tvalid_1's rmse: 180.257\n",
      "[1600]\ttraining's rmse: 47.1493\tvalid_1's rmse: 180.029\n",
      "[1700]\ttraining's rmse: 45.7858\tvalid_1's rmse: 179.8\n",
      "[1800]\ttraining's rmse: 44.483\tvalid_1's rmse: 179.665\n",
      "[1900]\ttraining's rmse: 43.3058\tvalid_1's rmse: 179.613\n",
      "[2000]\ttraining's rmse: 42.1901\tvalid_1's rmse: 179.52\n",
      "[2100]\ttraining's rmse: 41.1409\tvalid_1's rmse: 179.47\n",
      "[2200]\ttraining's rmse: 40.1553\tvalid_1's rmse: 179.38\n",
      "[2300]\ttraining's rmse: 39.207\tvalid_1's rmse: 179.315\n",
      "[2400]\ttraining's rmse: 38.2833\tvalid_1's rmse: 179.212\n",
      "[2500]\ttraining's rmse: 37.3902\tvalid_1's rmse: 179.139\n",
      "[2600]\ttraining's rmse: 36.5657\tvalid_1's rmse: 179.105\n",
      "[2700]\ttraining's rmse: 35.7179\tvalid_1's rmse: 179.059\n",
      "[2800]\ttraining's rmse: 34.951\tvalid_1's rmse: 179.018\n",
      "[2900]\ttraining's rmse: 34.1879\tvalid_1's rmse: 178.961\n",
      "[3000]\ttraining's rmse: 33.4612\tvalid_1's rmse: 178.858\n",
      "[3100]\ttraining's rmse: 32.7354\tvalid_1's rmse: 178.792\n",
      "[3200]\ttraining's rmse: 32.0604\tvalid_1's rmse: 178.737\n",
      "[3300]\ttraining's rmse: 31.4348\tvalid_1's rmse: 178.679\n",
      "[3400]\ttraining's rmse: 30.8355\tvalid_1's rmse: 178.645\n",
      "[3500]\ttraining's rmse: 30.2511\tvalid_1's rmse: 178.56\n",
      "[3600]\ttraining's rmse: 29.6787\tvalid_1's rmse: 178.524\n",
      "[3700]\ttraining's rmse: 29.1294\tvalid_1's rmse: 178.468\n",
      "[3800]\ttraining's rmse: 28.5998\tvalid_1's rmse: 178.398\n",
      "[3900]\ttraining's rmse: 28.0646\tvalid_1's rmse: 178.354\n",
      "[4000]\ttraining's rmse: 27.5572\tvalid_1's rmse: 178.331\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's rmse: 27.5572\tvalid_1's rmse: 178.331\n",
      "0.7316637175912708\n",
      "valid mean: 534.1872678030703\n",
      "true  mean: 531.319290465632\n",
      "test  mean: 441.00564207336595\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 329.871\tvalid_1's rmse: 387.11\n",
      "[200]\ttraining's rmse: 188.437\tvalid_1's rmse: 280.803\n",
      "[300]\ttraining's rmse: 130.57\tvalid_1's rmse: 258.312\n",
      "[400]\ttraining's rmse: 105.431\tvalid_1's rmse: 254.04\n",
      "[500]\ttraining's rmse: 92.1191\tvalid_1's rmse: 251.771\n",
      "[600]\ttraining's rmse: 83.1366\tvalid_1's rmse: 250.087\n",
      "[700]\ttraining's rmse: 76.4964\tvalid_1's rmse: 249.086\n",
      "[800]\ttraining's rmse: 71.2173\tvalid_1's rmse: 247.895\n",
      "[900]\ttraining's rmse: 67.0426\tvalid_1's rmse: 247.182\n",
      "[1000]\ttraining's rmse: 63.5394\tvalid_1's rmse: 246.496\n",
      "[1100]\ttraining's rmse: 60.5665\tvalid_1's rmse: 245.867\n",
      "[1200]\ttraining's rmse: 58.0973\tvalid_1's rmse: 245.357\n",
      "[1300]\ttraining's rmse: 55.954\tvalid_1's rmse: 245.096\n",
      "[1400]\ttraining's rmse: 54.0363\tvalid_1's rmse: 244.756\n",
      "[1500]\ttraining's rmse: 52.291\tvalid_1's rmse: 244.404\n",
      "[1600]\ttraining's rmse: 50.7116\tvalid_1's rmse: 244.27\n",
      "[1700]\ttraining's rmse: 49.2605\tvalid_1's rmse: 244.051\n",
      "[1800]\ttraining's rmse: 47.9164\tvalid_1's rmse: 243.892\n",
      "[1900]\ttraining's rmse: 46.6785\tvalid_1's rmse: 243.807\n",
      "[2000]\ttraining's rmse: 45.4869\tvalid_1's rmse: 243.692\n",
      "[2100]\ttraining's rmse: 44.3426\tvalid_1's rmse: 243.591\n",
      "[2200]\ttraining's rmse: 43.3066\tvalid_1's rmse: 243.399\n",
      "[2300]\ttraining's rmse: 42.2681\tvalid_1's rmse: 243.192\n",
      "[2400]\ttraining's rmse: 41.2981\tvalid_1's rmse: 243.072\n",
      "[2500]\ttraining's rmse: 40.3318\tvalid_1's rmse: 242.953\n",
      "[2600]\ttraining's rmse: 39.4031\tvalid_1's rmse: 242.838\n",
      "[2700]\ttraining's rmse: 38.4747\tvalid_1's rmse: 242.802\n",
      "[2800]\ttraining's rmse: 37.6097\tvalid_1's rmse: 242.675\n",
      "[2900]\ttraining's rmse: 36.7957\tvalid_1's rmse: 242.604\n",
      "[3000]\ttraining's rmse: 35.9983\tvalid_1's rmse: 242.556\n",
      "[3100]\ttraining's rmse: 35.2583\tvalid_1's rmse: 242.482\n",
      "[3200]\ttraining's rmse: 34.5081\tvalid_1's rmse: 242.437\n",
      "[3300]\ttraining's rmse: 33.7803\tvalid_1's rmse: 242.33\n",
      "[3400]\ttraining's rmse: 33.1198\tvalid_1's rmse: 242.279\n",
      "[3500]\ttraining's rmse: 32.4714\tvalid_1's rmse: 242.185\n",
      "[3600]\ttraining's rmse: 31.8697\tvalid_1's rmse: 242.115\n",
      "[3700]\ttraining's rmse: 31.2324\tvalid_1's rmse: 242.078\n",
      "[3800]\ttraining's rmse: 30.6178\tvalid_1's rmse: 242.006\n",
      "[3900]\ttraining's rmse: 30.0581\tvalid_1's rmse: 241.952\n",
      "[4000]\ttraining's rmse: 29.5172\tvalid_1's rmse: 241.888\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's rmse: 29.5172\tvalid_1's rmse: 241.888\n",
      "0.7059835235164662\n",
      "valid mean: 552.5842169962525\n",
      "true  mean: 577.2344789356985\n",
      "test  mean: 501.43420201707374\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 341.944\tvalid_1's rmse: 658.949\n",
      "[200]\ttraining's rmse: 196.811\tvalid_1's rmse: 524.165\n",
      "[300]\ttraining's rmse: 137.069\tvalid_1's rmse: 479.852\n",
      "[400]\ttraining's rmse: 111.144\tvalid_1's rmse: 460.527\n",
      "[500]\ttraining's rmse: 97.2203\tvalid_1's rmse: 449.952\n",
      "[600]\ttraining's rmse: 87.7335\tvalid_1's rmse: 444.254\n",
      "[700]\ttraining's rmse: 80.709\tvalid_1's rmse: 441.118\n",
      "[800]\ttraining's rmse: 75.2811\tvalid_1's rmse: 439.068\n",
      "[900]\ttraining's rmse: 70.8124\tvalid_1's rmse: 437.237\n",
      "[1000]\ttraining's rmse: 67.1531\tvalid_1's rmse: 435.923\n",
      "[1100]\ttraining's rmse: 64.0536\tvalid_1's rmse: 435.196\n",
      "[1200]\ttraining's rmse: 61.3917\tvalid_1's rmse: 434.347\n",
      "[1300]\ttraining's rmse: 59.019\tvalid_1's rmse: 433.776\n",
      "[1400]\ttraining's rmse: 56.9454\tvalid_1's rmse: 433.283\n",
      "[1500]\ttraining's rmse: 55.0576\tvalid_1's rmse: 432.822\n",
      "[1600]\ttraining's rmse: 53.4306\tvalid_1's rmse: 432.534\n",
      "[1700]\ttraining's rmse: 51.8783\tvalid_1's rmse: 432.257\n",
      "[1800]\ttraining's rmse: 50.3753\tvalid_1's rmse: 432.1\n",
      "[1900]\ttraining's rmse: 48.9671\tvalid_1's rmse: 431.83\n",
      "[2000]\ttraining's rmse: 47.6254\tvalid_1's rmse: 431.523\n",
      "[2100]\ttraining's rmse: 46.3485\tvalid_1's rmse: 431.249\n",
      "[2200]\ttraining's rmse: 45.1608\tvalid_1's rmse: 431.154\n",
      "[2300]\ttraining's rmse: 44.0879\tvalid_1's rmse: 431.021\n",
      "[2400]\ttraining's rmse: 43.0236\tvalid_1's rmse: 430.826\n",
      "[2500]\ttraining's rmse: 41.9924\tvalid_1's rmse: 430.774\n",
      "[2600]\ttraining's rmse: 40.9902\tvalid_1's rmse: 430.784\n",
      "[2700]\ttraining's rmse: 40.0409\tvalid_1's rmse: 430.671\n",
      "[2800]\ttraining's rmse: 39.0607\tvalid_1's rmse: 430.584\n",
      "[2900]\ttraining's rmse: 38.2082\tvalid_1's rmse: 430.448\n",
      "[3000]\ttraining's rmse: 37.4193\tvalid_1's rmse: 430.278\n",
      "[3100]\ttraining's rmse: 36.6647\tvalid_1's rmse: 430.29\n",
      "Early stopping, best iteration is:\n",
      "[3054]\ttraining's rmse: 37.0142\tvalid_1's rmse: 430.223\n",
      "0.5984536886185754\n",
      "valid mean: 610.8321203528969\n",
      "true  mean: 769.5532150776053\n",
      "test  mean: 511.9566833918641\n"
     ]
    }
   ],
   "source": [
    "data_df, stat_feat, y = get_stat_feature(data)\n",
    "m_type = 'lgb' \n",
    "    \n",
    "num_feat = stat_feat+['regYear']\n",
    "cate_feat = ['adcode','bodyType','model','regMonth']\n",
    "    \n",
    "if m_type == 'lgb':\n",
    "    for i in cate_feat:\n",
    "        data_df[i] = data_df[i].astype('category')\n",
    "elif m_type == 'xgb':\n",
    "    lbl = LabelEncoder()  \n",
    "    for i in tqdm(cate_feat):\n",
    "        data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "features = num_feat + cate_feat\n",
    "print(len(features), len(set(features))) \n",
    "\n",
    "for month in [0,1,2,3]: \n",
    "    sub,val_pred = get_train_model(data_df, month, y[month], m_type)   \n",
    "    data.loc[(data.regMonth==(month+1))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month+1))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "# sub['forecastVolum'] = np.expm1(sub['forecastVolum'].values)\n",
    "sub[['id','forecastVolum']].round().astype(int).to_csv('2_4_new_lgb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
